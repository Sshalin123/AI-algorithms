{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QYZUirpFsBLE"
      },
      "outputs": [],
      "source": [
        "## Speech Of DR APJ Abdul Kalam\n",
        "paragraph = \"\"\"Hello! I’m Shalin Shah, an undergraduate student at DJ Sanghvi College of Engineering, pursuing a Bachelor of Technology in Artificial Intelligence and Machine Learning (AIML). My journey into the world of technology and trading began early, driven by curiosity and a passion for learning.\n",
        "\n",
        "At the age of 16, I embarked on my trading journey, starting with analyzing DRHPs of IPO filings and eventually mastering swing trading. This experience honed my decision-making skills and cultivated my risk-taking appetite. My life so far has been less about sitting in lecture halls and more about immersing myself in experiences, managing risks, and applying my learnings to real-life scenarios.\n",
        "\n",
        "My academic journey has been enriched by a deep interest in AI and machine learning, particularly in generative AI and the functioning of large language models, inspired by collaborations with peers. Beyond academics.\n",
        "\n",
        "I gained hands-on experience as a Data Analyst with a reputed architect, where I demonstrated my networking and data collection abilities by engaging with sales heads across industries. Analyzed data from numerous clients and customers and used outputs to guide marketing and product strategies.\n",
        "\n",
        "Looking ahead, I am passionate about creating a transformative alternative to Bloomberg—leveraging technology to revolutionize financial data and trading insights. With a strong drive for innovation, a thirst for knowledge, and a collaborative spirit, I am always open to learning and working together to create impactful solutions.\n",
        "\n",
        "Let’s connect and turn ideas into reality!\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7v90j6MisBLJ"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kGTQ4ybKsBLL"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJ2skDpRsBLM",
        "outputId": "fdaf521b-62df-48bb-a0b9-de9277bd6aaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTQsaAossBLQ",
        "outputId": "39368eb2-6803-4949-9392-d840440e28c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " \"he'd\",\n",
              " \"he'll\",\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " \"he's\",\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " \"i'd\",\n",
              " 'if',\n",
              " \"i'll\",\n",
              " \"i'm\",\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it'd\",\n",
              " \"it'll\",\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " \"i've\",\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she'd\",\n",
              " \"she'll\",\n",
              " \"she's\",\n",
              " 'should',\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " \"should've\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " \"they'd\",\n",
              " \"they'll\",\n",
              " \"they're\",\n",
              " \"they've\",\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " \"we'd\",\n",
              " \"we'll\",\n",
              " \"we're\",\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " \"we've\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " 'your',\n",
              " \"you're\",\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " \"you've\"]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWXl0AqUsBLR",
        "outputId": "65218c17-93f2-4b9d-fb38-955a0275b44e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'aadi',\n",
              " 'aaj',\n",
              " 'aap',\n",
              " 'aapne',\n",
              " 'aata',\n",
              " 'aati',\n",
              " 'aaya',\n",
              " 'aaye',\n",
              " 'ab',\n",
              " 'abbe',\n",
              " 'abbey',\n",
              " 'abe',\n",
              " 'abhi',\n",
              " 'able',\n",
              " 'about',\n",
              " 'above',\n",
              " 'accha',\n",
              " 'according',\n",
              " 'accordingly',\n",
              " 'acha',\n",
              " 'achcha',\n",
              " 'across',\n",
              " 'actually',\n",
              " 'after',\n",
              " 'afterwards',\n",
              " 'again',\n",
              " 'against',\n",
              " 'agar',\n",
              " 'ain',\n",
              " 'aint',\n",
              " \"ain't\",\n",
              " 'aisa',\n",
              " 'aise',\n",
              " 'aisi',\n",
              " 'alag',\n",
              " 'all',\n",
              " 'allow',\n",
              " 'allows',\n",
              " 'almost',\n",
              " 'alone',\n",
              " 'along',\n",
              " 'already',\n",
              " 'also',\n",
              " 'although',\n",
              " 'always',\n",
              " 'am',\n",
              " 'among',\n",
              " 'amongst',\n",
              " 'an',\n",
              " 'and',\n",
              " 'andar',\n",
              " 'another',\n",
              " 'any',\n",
              " 'anybody',\n",
              " 'anyhow',\n",
              " 'anyone',\n",
              " 'anything',\n",
              " 'anyway',\n",
              " 'anyways',\n",
              " 'anywhere',\n",
              " 'ap',\n",
              " 'apan',\n",
              " 'apart',\n",
              " 'apna',\n",
              " 'apnaa',\n",
              " 'apne',\n",
              " 'apni',\n",
              " 'appear',\n",
              " 'are',\n",
              " 'aren',\n",
              " 'arent',\n",
              " \"aren't\",\n",
              " 'around',\n",
              " 'arre',\n",
              " 'as',\n",
              " 'aside',\n",
              " 'ask',\n",
              " 'asking',\n",
              " 'at',\n",
              " 'aur',\n",
              " 'avum',\n",
              " 'aya',\n",
              " 'aye',\n",
              " 'baad',\n",
              " 'baar',\n",
              " 'bad',\n",
              " 'bahut',\n",
              " 'bana',\n",
              " 'banae',\n",
              " 'banai',\n",
              " 'banao',\n",
              " 'banaya',\n",
              " 'banaye',\n",
              " 'banayi',\n",
              " 'banda',\n",
              " 'bande',\n",
              " 'bandi',\n",
              " 'bane',\n",
              " 'bani',\n",
              " 'bas',\n",
              " 'bata',\n",
              " 'batao',\n",
              " 'bc',\n",
              " 'be',\n",
              " 'became',\n",
              " 'because',\n",
              " 'become',\n",
              " 'becomes',\n",
              " 'becoming',\n",
              " 'been',\n",
              " 'before',\n",
              " 'beforehand',\n",
              " 'behind',\n",
              " 'being',\n",
              " 'below',\n",
              " 'beside',\n",
              " 'besides',\n",
              " 'best',\n",
              " 'better',\n",
              " 'between',\n",
              " 'beyond',\n",
              " 'bhai',\n",
              " 'bheetar',\n",
              " 'bhi',\n",
              " 'bhitar',\n",
              " 'bht',\n",
              " 'bilkul',\n",
              " 'bohot',\n",
              " 'bol',\n",
              " 'bola',\n",
              " 'bole',\n",
              " 'boli',\n",
              " 'bolo',\n",
              " 'bolta',\n",
              " 'bolte',\n",
              " 'bolti',\n",
              " 'both',\n",
              " 'brief',\n",
              " 'bro',\n",
              " 'btw',\n",
              " 'but',\n",
              " 'by',\n",
              " 'came',\n",
              " 'can',\n",
              " 'cannot',\n",
              " 'cant',\n",
              " \"can't\",\n",
              " 'cause',\n",
              " 'causes',\n",
              " 'certain',\n",
              " 'certainly',\n",
              " 'chahiye',\n",
              " 'chaiye',\n",
              " 'chal',\n",
              " 'chalega',\n",
              " 'chhaiye',\n",
              " 'clearly',\n",
              " \"c'mon\",\n",
              " 'com',\n",
              " 'come',\n",
              " 'comes',\n",
              " 'could',\n",
              " 'couldn',\n",
              " 'couldnt',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'de',\n",
              " 'dede',\n",
              " 'dega',\n",
              " 'degi',\n",
              " 'dekh',\n",
              " 'dekha',\n",
              " 'dekhe',\n",
              " 'dekhi',\n",
              " 'dekho',\n",
              " 'denge',\n",
              " 'dhang',\n",
              " 'di',\n",
              " 'did',\n",
              " 'didn',\n",
              " 'didnt',\n",
              " \"didn't\",\n",
              " 'dijiye',\n",
              " 'diya',\n",
              " 'diyaa',\n",
              " 'diye',\n",
              " 'diyo',\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " 'doesnt',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'done',\n",
              " 'dono',\n",
              " 'dont',\n",
              " \"don't\",\n",
              " 'doosra',\n",
              " 'doosre',\n",
              " 'down',\n",
              " 'downwards',\n",
              " 'dude',\n",
              " 'dunga',\n",
              " 'dungi',\n",
              " 'during',\n",
              " 'dusra',\n",
              " 'dusre',\n",
              " 'dusri',\n",
              " 'dvaara',\n",
              " 'dvara',\n",
              " 'dwaara',\n",
              " 'dwara',\n",
              " 'each',\n",
              " 'edu',\n",
              " 'eg',\n",
              " 'eight',\n",
              " 'either',\n",
              " 'ek',\n",
              " 'else',\n",
              " 'elsewhere',\n",
              " 'enough',\n",
              " 'etc',\n",
              " 'even',\n",
              " 'ever',\n",
              " 'every',\n",
              " 'everybody',\n",
              " 'everyone',\n",
              " 'everything',\n",
              " 'everywhere',\n",
              " 'ex',\n",
              " 'exactly',\n",
              " 'example',\n",
              " 'except',\n",
              " 'far',\n",
              " 'few',\n",
              " 'fifth',\n",
              " 'fir',\n",
              " 'first',\n",
              " 'five',\n",
              " 'followed',\n",
              " 'following',\n",
              " 'follows',\n",
              " 'for',\n",
              " 'forth',\n",
              " 'four',\n",
              " 'from',\n",
              " 'further',\n",
              " 'furthermore',\n",
              " 'gaya',\n",
              " 'gaye',\n",
              " 'gayi',\n",
              " 'get',\n",
              " 'gets',\n",
              " 'getting',\n",
              " 'ghar',\n",
              " 'given',\n",
              " 'gives',\n",
              " 'go',\n",
              " 'goes',\n",
              " 'going',\n",
              " 'gone',\n",
              " 'good',\n",
              " 'got',\n",
              " 'gotten',\n",
              " 'greetings',\n",
              " 'haan',\n",
              " 'had',\n",
              " 'hadd',\n",
              " 'hadn',\n",
              " 'hadnt',\n",
              " \"hadn't\",\n",
              " 'hai',\n",
              " 'hain',\n",
              " 'hamara',\n",
              " 'hamare',\n",
              " 'hamari',\n",
              " 'hamne',\n",
              " 'han',\n",
              " 'happens',\n",
              " 'har',\n",
              " 'hardly',\n",
              " 'has',\n",
              " 'hasn',\n",
              " 'hasnt',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " 'havent',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'hello',\n",
              " 'help',\n",
              " 'hence',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hereafter',\n",
              " 'hereby',\n",
              " 'herein',\n",
              " \"here's\",\n",
              " 'hereupon',\n",
              " 'hers',\n",
              " 'herself',\n",
              " \"he's\",\n",
              " 'hi',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'hither',\n",
              " 'hm',\n",
              " 'hmm',\n",
              " 'ho',\n",
              " 'hoga',\n",
              " 'hoge',\n",
              " 'hogi',\n",
              " 'hona',\n",
              " 'honaa',\n",
              " 'hone',\n",
              " 'honge',\n",
              " 'hongi',\n",
              " 'honi',\n",
              " 'hopefully',\n",
              " 'hota',\n",
              " 'hotaa',\n",
              " 'hote',\n",
              " 'hoti',\n",
              " 'how',\n",
              " 'howbeit',\n",
              " 'however',\n",
              " 'hoyenge',\n",
              " 'hoyengi',\n",
              " 'hu',\n",
              " 'hua',\n",
              " 'hue',\n",
              " 'huh',\n",
              " 'hui',\n",
              " 'hum',\n",
              " 'humein',\n",
              " 'humne',\n",
              " 'hun',\n",
              " 'huye',\n",
              " 'huyi',\n",
              " 'i',\n",
              " \"i'd\",\n",
              " 'idk',\n",
              " 'ie',\n",
              " 'if',\n",
              " \"i'll\",\n",
              " \"i'm\",\n",
              " 'imo',\n",
              " 'in',\n",
              " 'inasmuch',\n",
              " 'inc',\n",
              " 'inhe',\n",
              " 'inhi',\n",
              " 'inho',\n",
              " 'inka',\n",
              " 'inkaa',\n",
              " 'inke',\n",
              " 'inki',\n",
              " 'inn',\n",
              " 'inner',\n",
              " 'inse',\n",
              " 'insofar',\n",
              " 'into',\n",
              " 'inward',\n",
              " 'is',\n",
              " 'ise',\n",
              " 'isi',\n",
              " 'iska',\n",
              " 'iskaa',\n",
              " 'iske',\n",
              " 'iski',\n",
              " 'isme',\n",
              " 'isn',\n",
              " 'isne',\n",
              " 'isnt',\n",
              " \"isn't\",\n",
              " 'iss',\n",
              " 'isse',\n",
              " 'issi',\n",
              " 'isski',\n",
              " 'it',\n",
              " \"it'd\",\n",
              " \"it'll\",\n",
              " 'itna',\n",
              " 'itne',\n",
              " 'itni',\n",
              " 'itno',\n",
              " 'its',\n",
              " \"it's\",\n",
              " 'itself',\n",
              " 'ityaadi',\n",
              " 'ityadi',\n",
              " \"i've\",\n",
              " 'ja',\n",
              " 'jaa',\n",
              " 'jab',\n",
              " 'jabh',\n",
              " 'jaha',\n",
              " 'jahaan',\n",
              " 'jahan',\n",
              " 'jaisa',\n",
              " 'jaise',\n",
              " 'jaisi',\n",
              " 'jata',\n",
              " 'jayega',\n",
              " 'jidhar',\n",
              " 'jin',\n",
              " 'jinhe',\n",
              " 'jinhi',\n",
              " 'jinho',\n",
              " 'jinhone',\n",
              " 'jinka',\n",
              " 'jinke',\n",
              " 'jinki',\n",
              " 'jinn',\n",
              " 'jis',\n",
              " 'jise',\n",
              " 'jiska',\n",
              " 'jiske',\n",
              " 'jiski',\n",
              " 'jisme',\n",
              " 'jiss',\n",
              " 'jisse',\n",
              " 'jitna',\n",
              " 'jitne',\n",
              " 'jitni',\n",
              " 'jo',\n",
              " 'just',\n",
              " 'jyaada',\n",
              " 'jyada',\n",
              " 'k',\n",
              " 'ka',\n",
              " 'kaafi',\n",
              " 'kab',\n",
              " 'kabhi',\n",
              " 'kafi',\n",
              " 'kaha',\n",
              " 'kahaa',\n",
              " 'kahaan',\n",
              " 'kahan',\n",
              " 'kahi',\n",
              " 'kahin',\n",
              " 'kahte',\n",
              " 'kaisa',\n",
              " 'kaise',\n",
              " 'kaisi',\n",
              " 'kal',\n",
              " 'kam',\n",
              " 'kar',\n",
              " 'kara',\n",
              " 'kare',\n",
              " 'karega',\n",
              " 'karegi',\n",
              " 'karen',\n",
              " 'karenge',\n",
              " 'kari',\n",
              " 'karke',\n",
              " 'karna',\n",
              " 'karne',\n",
              " 'karni',\n",
              " 'karo',\n",
              " 'karta',\n",
              " 'karte',\n",
              " 'karti',\n",
              " 'karu',\n",
              " 'karun',\n",
              " 'karunga',\n",
              " 'karungi',\n",
              " 'kaun',\n",
              " 'kaunsa',\n",
              " 'kayi',\n",
              " 'kch',\n",
              " 'ke',\n",
              " 'keep',\n",
              " 'keeps',\n",
              " 'keh',\n",
              " 'kehte',\n",
              " 'kept',\n",
              " 'khud',\n",
              " 'ki',\n",
              " 'kin',\n",
              " 'kine',\n",
              " 'kinhe',\n",
              " 'kinho',\n",
              " 'kinka',\n",
              " 'kinke',\n",
              " 'kinki',\n",
              " 'kinko',\n",
              " 'kinn',\n",
              " 'kino',\n",
              " 'kis',\n",
              " 'kise',\n",
              " 'kisi',\n",
              " 'kiska',\n",
              " 'kiske',\n",
              " 'kiski',\n",
              " 'kisko',\n",
              " 'kisliye',\n",
              " 'kisne',\n",
              " 'kitna',\n",
              " 'kitne',\n",
              " 'kitni',\n",
              " 'kitno',\n",
              " 'kiya',\n",
              " 'kiye',\n",
              " 'know',\n",
              " 'known',\n",
              " 'knows',\n",
              " 'ko',\n",
              " 'koi',\n",
              " 'kon',\n",
              " 'konsa',\n",
              " 'koyi',\n",
              " 'krna',\n",
              " 'krne',\n",
              " 'kuch',\n",
              " 'kuchch',\n",
              " 'kuchh',\n",
              " 'kul',\n",
              " 'kull',\n",
              " 'kya',\n",
              " 'kyaa',\n",
              " 'kyu',\n",
              " 'kyuki',\n",
              " 'kyun',\n",
              " 'kyunki',\n",
              " 'lagta',\n",
              " 'lagte',\n",
              " 'lagti',\n",
              " 'last',\n",
              " 'lately',\n",
              " 'later',\n",
              " 'le',\n",
              " 'least',\n",
              " 'lekar',\n",
              " 'lekin',\n",
              " 'less',\n",
              " 'lest',\n",
              " 'let',\n",
              " \"let's\",\n",
              " 'li',\n",
              " 'like',\n",
              " 'liked',\n",
              " 'likely',\n",
              " 'little',\n",
              " 'liya',\n",
              " 'liye',\n",
              " 'll',\n",
              " 'lo',\n",
              " 'log',\n",
              " 'logon',\n",
              " 'lol',\n",
              " 'look',\n",
              " 'looking',\n",
              " 'looks',\n",
              " 'ltd',\n",
              " 'lunga',\n",
              " 'm',\n",
              " 'maan',\n",
              " 'maana',\n",
              " 'maane',\n",
              " 'maani',\n",
              " 'maano',\n",
              " 'magar',\n",
              " 'mai',\n",
              " 'main',\n",
              " 'maine',\n",
              " 'mainly',\n",
              " 'mana',\n",
              " 'mane',\n",
              " 'mani',\n",
              " 'mano',\n",
              " 'many',\n",
              " 'mat',\n",
              " 'may',\n",
              " 'maybe',\n",
              " 'me',\n",
              " 'mean',\n",
              " 'meanwhile',\n",
              " 'mein',\n",
              " 'mera',\n",
              " 'mere',\n",
              " 'merely',\n",
              " 'meri',\n",
              " 'might',\n",
              " 'mightn',\n",
              " 'mightnt',\n",
              " \"mightn't\",\n",
              " 'mil',\n",
              " 'mjhe',\n",
              " 'more',\n",
              " 'moreover',\n",
              " 'most',\n",
              " 'mostly',\n",
              " 'much',\n",
              " 'mujhe',\n",
              " 'must',\n",
              " 'mustn',\n",
              " 'mustnt',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'na',\n",
              " 'naa',\n",
              " 'naah',\n",
              " 'nahi',\n",
              " 'nahin',\n",
              " 'nai',\n",
              " 'name',\n",
              " 'namely',\n",
              " 'nd',\n",
              " 'ne',\n",
              " 'near',\n",
              " 'nearly',\n",
              " 'necessary',\n",
              " 'neeche',\n",
              " 'need',\n",
              " 'needn',\n",
              " 'neednt',\n",
              " \"needn't\",\n",
              " 'needs',\n",
              " 'neither',\n",
              " 'never',\n",
              " 'nevertheless',\n",
              " 'new',\n",
              " 'next',\n",
              " 'nhi',\n",
              " 'nine',\n",
              " 'no',\n",
              " 'nobody',\n",
              " 'non',\n",
              " 'none',\n",
              " 'noone',\n",
              " 'nope',\n",
              " 'nor',\n",
              " 'normally',\n",
              " 'not',\n",
              " 'nothing',\n",
              " 'novel',\n",
              " 'now',\n",
              " 'nowhere',\n",
              " 'o',\n",
              " 'obviously',\n",
              " 'of',\n",
              " 'off',\n",
              " 'often',\n",
              " 'oh',\n",
              " 'ok',\n",
              " 'okay',\n",
              " 'old',\n",
              " 'on',\n",
              " 'once',\n",
              " 'one',\n",
              " 'ones',\n",
              " 'only',\n",
              " 'onto',\n",
              " 'or',\n",
              " 'other',\n",
              " 'others',\n",
              " 'otherwise',\n",
              " 'ought',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'outside',\n",
              " 'over',\n",
              " 'overall',\n",
              " 'own',\n",
              " 'par',\n",
              " 'pata',\n",
              " 'pe',\n",
              " 'pehla',\n",
              " 'pehle',\n",
              " 'pehli',\n",
              " 'people',\n",
              " 'per',\n",
              " 'perhaps',\n",
              " 'phla',\n",
              " 'phle',\n",
              " 'phli',\n",
              " 'placed',\n",
              " 'please',\n",
              " 'plus',\n",
              " 'poora',\n",
              " 'poori',\n",
              " 'provides',\n",
              " 'pura',\n",
              " 'puri',\n",
              " 'q',\n",
              " 'que',\n",
              " 'quite',\n",
              " 'raha',\n",
              " 'rahaa',\n",
              " 'rahe',\n",
              " 'rahi',\n",
              " 'rakh',\n",
              " 'rakha',\n",
              " 'rakhe',\n",
              " 'rakhen',\n",
              " 'rakhi',\n",
              " 'rakho',\n",
              " 'rather',\n",
              " 're',\n",
              " 'really',\n",
              " 'reasonably',\n",
              " 'regarding',\n",
              " 'regardless',\n",
              " 'regards',\n",
              " 'rehte',\n",
              " 'rha',\n",
              " 'rhaa',\n",
              " 'rhe',\n",
              " 'rhi',\n",
              " 'ri',\n",
              " 'right',\n",
              " 's',\n",
              " 'sa',\n",
              " 'saara',\n",
              " 'saare',\n",
              " 'saath',\n",
              " 'sab',\n",
              " 'sabhi',\n",
              " 'sabse',\n",
              " 'sahi',\n",
              " 'said',\n",
              " 'sakta',\n",
              " 'saktaa',\n",
              " 'sakte',\n",
              " 'sakti',\n",
              " 'same',\n",
              " 'sang',\n",
              " 'sara',\n",
              " 'sath',\n",
              " 'saw',\n",
              " 'say',\n",
              " 'saying',\n",
              " 'says',\n",
              " 'se',\n",
              " 'second',\n",
              " 'secondly',\n",
              " 'see',\n",
              " 'seeing',\n",
              " 'seem',\n",
              " 'seemed',\n",
              " 'seeming',\n",
              " 'seems',\n",
              " 'seen',\n",
              " 'self',\n",
              " 'selves',\n",
              " 'sensible',\n",
              " 'sent',\n",
              " 'serious',\n",
              " 'seriously',\n",
              " 'seven',\n",
              " 'several',\n",
              " 'shall',\n",
              " 'shan',\n",
              " 'shant',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " 'shouldn',\n",
              " 'shouldnt',\n",
              " \"shouldn't\",\n",
              " \"should've\",\n",
              " 'si',\n",
              " 'since',\n",
              " 'six',\n",
              " 'so',\n",
              " 'soch',\n",
              " 'some',\n",
              " 'somebody',\n",
              " 'somehow',\n",
              " 'someone',\n",
              " 'something',\n",
              " 'sometime',\n",
              " 'sometimes',\n",
              " 'somewhat',\n",
              " 'somewhere',\n",
              " 'soon',\n",
              " 'still',\n",
              " 'sub',\n",
              " 'such',\n",
              " 'sup',\n",
              " 'sure',\n",
              " 't',\n",
              " 'tab',\n",
              " 'tabh',\n",
              " 'tak',\n",
              " 'take',\n",
              " 'taken',\n",
              " 'tarah',\n",
              " 'teen',\n",
              " 'teeno',\n",
              " 'teesra',\n",
              " 'teesre',\n",
              " 'teesri',\n",
              " 'tell',\n",
              " 'tends',\n",
              " 'tera',\n",
              " 'tere',\n",
              " 'teri',\n",
              " 'th',\n",
              " 'tha',\n",
              " 'than',\n",
              " 'thank',\n",
              " 'thanks',\n",
              " 'thanx',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'thats',\n",
              " \"that's\",\n",
              " 'the',\n",
              " 'theek',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'thence',\n",
              " 'there',\n",
              " 'thereafter',\n",
              " 'thereby',\n",
              " 'therefore',\n",
              " 'therein',\n",
              " 'theres',\n",
              " \"there's\",\n",
              " 'thereupon',\n",
              " 'these',\n",
              " 'they',\n",
              " \"they'd\",\n",
              " \"they'll\",\n",
              " \"they're\",\n",
              " \"they've\",\n",
              " 'thi',\n",
              " 'thik',\n",
              " 'thing',\n",
              " 'think',\n",
              " 'thinking',\n",
              " 'third',\n",
              " 'this',\n",
              " 'tho',\n",
              " 'thoda',\n",
              " 'thodi',\n",
              " 'thorough',\n",
              " 'thoroughly',\n",
              " 'those',\n",
              " 'though',\n",
              " 'thought',\n",
              " 'three',\n",
              " 'through',\n",
              " 'throughout',\n",
              " 'thru',\n",
              " 'thus',\n",
              " 'tjhe',\n",
              " 'to',\n",
              " 'together',\n",
              " 'toh',\n",
              " 'too',\n",
              " 'took',\n",
              " 'toward',\n",
              " 'towards',\n",
              " 'tried',\n",
              " 'tries',\n",
              " 'true',\n",
              " 'truly',\n",
              " 'try',\n",
              " 'trying',\n",
              " 'tu',\n",
              " 'tujhe',\n",
              " 'tum',\n",
              " 'tumhara',\n",
              " 'tumhare',\n",
              " 'tumhari',\n",
              " 'tune',\n",
              " 'twice',\n",
              " 'two',\n",
              " 'um',\n",
              " 'umm',\n",
              " 'un',\n",
              " 'under',\n",
              " 'unhe',\n",
              " 'unhi',\n",
              " 'unho',\n",
              " 'unhone',\n",
              " 'unka',\n",
              " 'unkaa',\n",
              " 'unke',\n",
              " 'unki',\n",
              " 'unko',\n",
              " 'unless',\n",
              " 'unlikely',\n",
              " 'unn',\n",
              " 'unse',\n",
              " 'until',\n",
              " 'unto',\n",
              " 'up',\n",
              " 'upar',\n",
              " 'upon',\n",
              " 'us',\n",
              " 'use',\n",
              " 'used',\n",
              " 'useful',\n",
              " 'uses',\n",
              " 'usi',\n",
              " 'using',\n",
              " 'uska',\n",
              " 'uske',\n",
              " 'usne',\n",
              " 'uss',\n",
              " 'usse',\n",
              " 'ussi',\n",
              " 'usually',\n",
              " 'vaala',\n",
              " 'vaale',\n",
              " 'vaali',\n",
              " 'vahaan',\n",
              " 'vahan',\n",
              " 'vahi',\n",
              " 'vahin',\n",
              " 'vaisa',\n",
              " 'vaise',\n",
              " 'vaisi',\n",
              " 'vala',\n",
              " 'vale',\n",
              " 'vali',\n",
              " 'various',\n",
              " 've',\n",
              " 'very',\n",
              " 'via',\n",
              " 'viz',\n",
              " 'vo',\n",
              " 'waala',\n",
              " 'waale',\n",
              " 'waali',\n",
              " 'wagaira',\n",
              " 'wagairah',\n",
              " 'wagerah',\n",
              " 'waha',\n",
              " 'wahaan',\n",
              " 'wahan',\n",
              " 'wahi',\n",
              " 'wahin',\n",
              " 'waisa',\n",
              " 'waise',\n",
              " 'waisi',\n",
              " 'wala',\n",
              " 'wale',\n",
              " 'wali',\n",
              " 'want',\n",
              " 'wants',\n",
              " 'was',\n",
              " 'wasn',\n",
              " 'wasnt',\n",
              " \"wasn't\",\n",
              " 'way',\n",
              " 'we',\n",
              " \"we'd\",\n",
              " 'well',\n",
              " \"we'll\",\n",
              " 'went',\n",
              " 'were',\n",
              " \"we're\",\n",
              " 'weren',\n",
              " 'werent',\n",
              " \"weren't\",\n",
              " \"we've\",\n",
              " 'what',\n",
              " 'whatever',\n",
              " \"what's\",\n",
              " 'when',\n",
              " 'whence',\n",
              " 'whenever',\n",
              " 'where',\n",
              " 'whereafter',\n",
              " 'whereas',\n",
              " 'whereby',\n",
              " 'wherein',\n",
              " \"where's\",\n",
              " 'whereupon',\n",
              " 'wherever',\n",
              " 'whether',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whoever',\n",
              " 'whole',\n",
              " 'whom',\n",
              " \"who's\",\n",
              " 'whose',\n",
              " 'why',\n",
              " 'will',\n",
              " 'willing',\n",
              " 'with',\n",
              " 'within',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "stopwords.words('hinglish')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words('tamil')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCh1q5RjtxF_",
        "outputId": "2a62296c-dba2-46e8-bc79-d6d4fb6b4068"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['அங்கு',\n",
              " 'அங்கே',\n",
              " 'அடுத்த',\n",
              " 'அதனால்',\n",
              " 'அதன்',\n",
              " 'அதற்கு',\n",
              " 'அதிக',\n",
              " 'அதில்',\n",
              " 'அது',\n",
              " 'அதே',\n",
              " 'அதை',\n",
              " 'அந்த',\n",
              " 'அந்தக்',\n",
              " 'அந்தப்',\n",
              " 'அன்று',\n",
              " 'அல்லது',\n",
              " 'அவன்',\n",
              " 'அவரது',\n",
              " 'அவர்',\n",
              " 'அவர்கள்',\n",
              " 'அவள்',\n",
              " 'அவை',\n",
              " 'ஆகிய',\n",
              " 'ஆகியோர்',\n",
              " 'ஆகும்',\n",
              " 'இங்கு',\n",
              " 'இங்கே',\n",
              " 'இடத்தில்',\n",
              " 'இடம்',\n",
              " 'இதனால்',\n",
              " 'இதனை',\n",
              " 'இதன்',\n",
              " 'இதற்கு',\n",
              " 'இதில்',\n",
              " 'இது',\n",
              " 'இதை',\n",
              " 'இந்த',\n",
              " 'இந்தக்',\n",
              " 'இந்தத்',\n",
              " 'இந்தப்',\n",
              " 'இன்னும்',\n",
              " 'இப்போது',\n",
              " 'இரு',\n",
              " 'இருக்கும்',\n",
              " 'இருந்த',\n",
              " 'இருந்தது',\n",
              " 'இருந்து',\n",
              " 'இவர்',\n",
              " 'இவை',\n",
              " 'உன்',\n",
              " 'உள்ள',\n",
              " 'உள்ளது',\n",
              " 'உள்ளன',\n",
              " 'எந்த',\n",
              " 'என',\n",
              " 'எனக்',\n",
              " 'எனக்கு',\n",
              " 'எனப்படும்',\n",
              " 'எனவும்',\n",
              " 'எனவே',\n",
              " 'எனினும்',\n",
              " 'எனும்',\n",
              " 'என்',\n",
              " 'என்ன',\n",
              " 'என்னும்',\n",
              " 'என்பது',\n",
              " 'என்பதை',\n",
              " 'என்ற',\n",
              " 'என்று',\n",
              " 'என்றும்',\n",
              " 'எல்லாம்',\n",
              " 'ஏன்',\n",
              " 'ஒரு',\n",
              " 'ஒரே',\n",
              " 'ஓர்',\n",
              " 'கொண்ட',\n",
              " 'கொண்டு',\n",
              " 'கொள்ள',\n",
              " 'சற்று',\n",
              " 'சிறு',\n",
              " 'சில',\n",
              " 'சேர்ந்த',\n",
              " 'தனது',\n",
              " 'தன்',\n",
              " 'தவிர',\n",
              " 'தான்',\n",
              " 'நான்',\n",
              " 'நாம்',\n",
              " 'நீ',\n",
              " 'பற்றி',\n",
              " 'பற்றிய',\n",
              " 'பல',\n",
              " 'பலரும்',\n",
              " 'பல்வேறு',\n",
              " 'பின்',\n",
              " 'பின்னர்',\n",
              " 'பிற',\n",
              " 'பிறகு',\n",
              " 'பெரும்',\n",
              " 'பேர்',\n",
              " 'போது',\n",
              " 'போன்ற',\n",
              " 'போல',\n",
              " 'போல்',\n",
              " 'மட்டுமே',\n",
              " 'மட்டும்',\n",
              " 'மற்ற',\n",
              " 'மற்றும்',\n",
              " 'மிக',\n",
              " 'மிகவும்',\n",
              " 'மீது',\n",
              " 'முதல்',\n",
              " 'முறை',\n",
              " 'மேலும்',\n",
              " 'மேல்',\n",
              " 'யார்',\n",
              " 'வந்த',\n",
              " 'வந்து',\n",
              " 'வரும்',\n",
              " 'வரை',\n",
              " 'வரையில்',\n",
              " 'விட',\n",
              " 'விட்டு',\n",
              " 'வேண்டும்',\n",
              " 'வேறு']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XklNt9HVsBLR"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HAfq5A50sBLS"
      },
      "outputs": [],
      "source": [
        "stemmer=PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee5a47ef",
        "outputId": "97931280-8be4-4b3b-b084-ac560dbdd2bd"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nbcoAQ89sBLT"
      },
      "outputs": [],
      "source": [
        "sentences=nltk.sent_tokenize(paragraph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCEZGAx7sBLT",
        "outputId": "74b9d0f1-1004-4efb-e9d1-97914d205a53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "type(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply Stopwords And Filter And then Apply Stemming\n"
      ],
      "metadata": {
        "id": "Yt0V876nsRQz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QLeTmD7gsBLU"
      },
      "outputs": [],
      "source": [
        "\n",
        "for i in range(len(sentences)):\n",
        "    words=nltk.word_tokenize(sentences[i])\n",
        "    words=[stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
        "    sentences[i]=' '.join(words)# converting all the list of words into sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vCPtVRlsBLV",
        "outputId": "aae0b5be-f970-40f2-9a50-7193b5c110ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello !',\n",
              " 'i ’ shalin shah , undergradu student dj sanghvi colleg engin , pursu bachelor technolog artifici intellig machin learn ( aiml ) .',\n",
              " 'my journey world technolog trade began earli , driven curios passion learn .',\n",
              " 'at age 16 , i embark trade journey , start analyz drhp ipo file eventu master swing trade .',\n",
              " 'thi experi hone decision-mak skill cultiv risk-tak appetit .',\n",
              " 'my life far less sit lectur hall immers experi , manag risk , appli learn real-lif scenario .',\n",
              " 'my academ journey enrich deep interest ai machin learn , particularli gener ai function larg languag model , inspir collabor peer .',\n",
              " 'beyond academ .',\n",
              " 'i gain hands-on experi data analyst reput architect , i demonstr network data collect abil engag sale head across industri .',\n",
              " 'analyz data numer client custom use output guid market product strategi .',\n",
              " 'look ahead , i passion creat transform altern bloomberg—leverag technolog revolution financi data trade insight .',\n",
              " 'with strong drive innov , thirst knowledg , collabor spirit , i alway open learn work togeth creat impact solut .',\n",
              " 'let ’ connect turn idea realiti !']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Rd3Wm-EEsBLV"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "snowballstemmer=SnowballStemmer('english')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply Stopwords And Filter And then Apply Snowball Stemming\n"
      ],
      "metadata": {
        "id": "36zpDv4-sUyY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "27tGLjMNsBLW"
      },
      "outputs": [],
      "source": [
        "\n",
        "for i in range(len(sentences)):\n",
        "    words=nltk.word_tokenize(sentences[i])\n",
        "    words=[snowballstemmer.stem(word) for word in words if word not in set(stopwords.words('tamil'))]\n",
        "    sentences[i]=' '.join(words)# converting all the list of words into sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSbw_p7PsBLW",
        "outputId": "328fd16b-97fc-435d-946a-9f6e21659383"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['!',\n",
              " '’ shalin shah , undergradu student dj sanghvi colleg engin , pursu bachelor technolog artifici intellig machin learn ( aiml ) .',\n",
              " 'journey world technolog trade begin ear , drive curio passion learn .',\n",
              " 'age 16 , embark trade journey , start analyz drhp ipo file eventu master swing trade .',\n",
              " 'experi decision-mak skill cultiv risk-tak appetit .',\n",
              " 'life sit lectur hall immer experi , manag risk , appli learn real-lif scenario .',\n",
              " 'academ journey enrich deep interest ai machin learn , particular gener ai function larg languag model , inspir collabor peer .',\n",
              " 'academ .',\n",
              " 'gain hands-on experi data analyst reput architect , demonstr network data collect abil engag sale head industri .',\n",
              " 'analyz data numer client custom output guid market product strategi .',\n",
              " 'ahead , passion creat transform altern bloomberg—leverag technolog revolut financ data trade insight .',\n",
              " 'strong drive innov , thirst knowledg , collabor spirit , alway open learn work togeth creat impact solut .',\n",
              " '’ connect turn idea realiti !']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "SF84on6LsBLX"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer=WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply Stopwords And Filter And then Apply Snowball Stemming\n"
      ],
      "metadata": {
        "id": "jFUoSmmqsasR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17e47f98",
        "outputId": "7ac8680e-0f68-4a11-bd88-c04f17e2612e"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "qLBTmG5isBLX"
      },
      "outputs": [],
      "source": [
        "\n",
        "for i in range(len(sentences)):\n",
        "    #sentences[i]=sentences[i].lower()\n",
        "    words=nltk.word_tokenize(sentences[i])\n",
        "    words=[lemmatizer.lemmatize(word.lower(),pos='v') for word in words if word not in set(stopwords.words('english'))]\n",
        "    sentences[i]=' '.join(words)# converting all the list of words into sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4HK3oTksBLX",
        "outputId": "83676366-79ad-4aff-a9b6-1b9acbf965b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['!',\n",
              " '’ shalin shah , undergradu student dj sanghvi colleg engin , pursu bachelor technolog artifici intellig machin learn ( aiml ) .',\n",
              " 'journey world technolog trade begin ear , drive curio passion learn .',\n",
              " 'age 16 , embark trade journey , start analyz drhp ipo file eventu master swing trade .',\n",
              " 'experi decision-mak skill cultiv risk-tak appetit .',\n",
              " 'life sit lectur hall immer experi , manag risk , appli learn real-lif scenario .',\n",
              " 'academ journey enrich deep interest ai machin learn , particular gener ai function larg languag model , inspir collabor peer .',\n",
              " 'academ .',\n",
              " 'gain hands-on experi data analyst reput architect , demonstr network data collect abil engag sale head industri .',\n",
              " 'analyz data numer client custom output guid market product strategi .',\n",
              " 'ahead , passion creat transform altern bloomberg—leverag technolog revolut financ data trade insight .',\n",
              " 'strong drive innov , thirst knowledg , collabor spirit , alway open learn work togeth creat impact solut .',\n",
              " '’ connect turn idea realiti !']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "p-s7_GG9sBLY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f53d398a"
      },
      "source": [
        "The error `LookupError: Resource punkt_tab not found.` means that the necessary data for the `nltk.sent_tokenize()` function is not available. We need to download it using `nltk.download('punkt_tab')`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfa7f4aa"
      },
      "source": [
        "The traceback indicates that the `wordnet` resource is missing. I will download it using `nltk.download('wordnet')`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "567a3320",
        "outputId": "578596f6-4ca2-4125-9dce-f68448a040a6"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "print(stopwords.fileids())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['albanian', 'arabic', 'azerbaijani', 'basque', 'belarusian', 'bengali', 'catalan', 'chinese', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hebrew', 'hinglish', 'hungarian', 'indonesian', 'italian', 'kazakh', 'nepali', 'norwegian', 'portuguese', 'romanian', 'russian', 'slovene', 'spanish', 'swedish', 'tajik', 'tamil', 'turkish']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
