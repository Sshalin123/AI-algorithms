{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sshalin123/AI-algorithms/blob/main/StemminG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVj8x3EYgVY1"
      },
      "source": [
        "## Stemming\n",
        "Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma. Stemming is important in natural language understanding (NLU) and natural language processing (NLP).\n",
        "\n",
        "For example:\n",
        "\n",
        "\"running\" → \"run\"\n",
        "\n",
        "\"happiness\" → \"happi\"\n",
        "\n",
        "\"studies\" → \"studi\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification Problem\n",
        "## Comments of product is a positive review or negative review\n",
        "## Reviews----> eating, eat,eaten [going,gone,goes]--->go"
      ],
      "metadata": {
        "id": "6bDwRJejgnKB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1g5TfwigVY5"
      },
      "outputs": [],
      "source": [
        "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalized\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utStQ9PSgVY7"
      },
      "source": [
        "## porter stemmer\n",
        "is a rule-based algorithm for stemming English words.\n",
        "It is one of the most widely used stemmers, especially in:\n",
        "\n",
        "Search engines\n",
        "\n",
        "Text classification\n",
        "\n",
        "Information retrieval\n",
        "\n",
        "Step-by-Step Example:\n",
        "Let’s stem the word \"relational\":\n",
        "\n",
        "Start with: relational\n",
        "\n",
        "Remove -al (common suffix): relation\n",
        "\n",
        "Remove -ion (another suffix): relate\n",
        "\n",
        "But Porter stops at relate → \"relat\" because it aims to reach a minimal form, not a dictionary word.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEkDrZUbgVY7"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJId_f1egVY8"
      },
      "outputs": [],
      "source": [
        "stemming=PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-RbxDO6gVY8",
        "outputId": "4797c317-c792-4bff-b3f5-edafb4990120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating---->eat\n",
            "eats---->eat\n",
            "eaten---->eaten\n",
            "writing---->write\n",
            "writes---->write\n",
            "programming---->program\n",
            "programs---->program\n",
            "history---->histori\n",
            "finally---->final\n",
            "finalized---->final\n"
          ]
        }
      ],
      "source": [
        "for word in words:\n",
        "    print(word+\"---->\"+stemming.stem(word))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qsPogWcfgVY-",
        "outputId": "5cb3f23d-d0d3-4528-b737-7b1a76a937a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "stemming.stem('eating')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "oqbohzuigVY_",
        "outputId": "4f789805-f5e6-42e3-8d77-0b70d2b8912c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fuck'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "stemming.stem(\"fucking\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Issue              | Explanation                                              |\n",
        "| ------------------ | -------------------------------------------------------- |\n",
        "| Over-stemming      | `\"universe\"` → `\"univers\"` (might group unrelated words) |\n",
        "| Under-stemming     | `\"organize\"` vs `\"organising\"` may not match             |\n",
        "| Not Language-Aware | Only works for English and similar rule-based languages  |\n"
      ],
      "metadata": {
        "id": "D9PR5JZehZTw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlVDyb2ngVZA"
      },
      "source": [
        "### RegexpStemmer class\n",
        "NLTK has RegexpStemmer class with the help of which we can easily implement Regular Expression Stemmer algorithms. It basically takes a single regular expression and removes any prefix or suffix that matches the expression. Let us see an example\n",
        "\n",
        "The RegexpStemmer is a stemmer class in the nltk.stem module that uses regex patterns to define how words should be stemmed.\n",
        "\n",
        "Unlike Porter or Snowball stemmers (which have many built-in rules), you define your own rules using regular expressions.\n",
        "\n",
        "How It Works\n",
        "\n",
        "It looks for suffixes that match the regular expression.\n",
        "\n",
        "If found, it removes them.\n",
        "\n",
        "Only applies if the resulting stem is at least min characters long."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cMXdLvhgVZA"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import RegexpStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "R-kVCs5fgVZB"
      },
      "outputs": [],
      "source": [
        "reg_stemmer=RegexpStemmer('ing$|s$|e$|able$', min=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ZgVZnGXZgVZB",
        "outputId": "0f8755ce-8258-46cb-d31e-381657c27bfc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "reg_stemmer.stem('eating')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "KuelE6ScgVZC",
        "outputId": "3da96686-b312-4b8f-9dd1-f375ea7a0100"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dripp'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "reg_stemmer.stem('dripping')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRx3qyi-gVZC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEb96UB4gVZD"
      },
      "source": [
        "### Snowball Stemmer\n",
        " It is a stemming algorithm which is also known as the Porter2 stemming algorithm as it is a better version of the Porter Stemmer since some issues of it were fixed in this stemmer.\n",
        "\n",
        " What is the Snowball Stemmer?\n",
        "\n",
        "The stemmer:\n",
        "\n",
        "Normalizes words (lowercasing, etc.)\n",
        "\n",
        "Removes suffixes based on a set of language-specific rules\n",
        "\n",
        "Produces stems (root forms), not necessarily valid words\n",
        "\n",
        "It applies more consistent and powerful rules than the Porter stemmer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUcH0aYIgVZD"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import SnowballStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_R8JAaZgVZD"
      },
      "outputs": [],
      "source": [
        "snowballsstemmer=SnowballStemmer('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnupuZYzgVZE",
        "outputId": "61b50067-075b-4807-914e-f4835a36e25d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating---->eat\n",
            "eats---->eat\n",
            "eaten---->eaten\n",
            "writing---->write\n",
            "writes---->write\n",
            "programming---->program\n",
            "programs---->program\n",
            "history---->histori\n",
            "finally---->final\n",
            "finalized---->final\n"
          ]
        }
      ],
      "source": [
        "for word in words:\n",
        "    print(word+\"---->\"+snowballsstemmer.stem(word))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCWnA8QKgVZF",
        "outputId": "bbc37194-e978-4d27-f86f-be0558ce3a11"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('sili', 'lili')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "stemming.stem(\"sily\"),stemming.stem(\"lily\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFCsNG54gVZF",
        "outputId": "a8fc7151-9289-48b7-fbcd-3699b2b7b84a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('fair', 'sport')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "snowballsstemmer.stem(\"fairly\"),snowballsstemmer.stem(\"sportingly\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "G6yFwxmDgVZG",
        "outputId": "eaab815f-d924-4fb2-960f-fc08937ab577"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gose'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "snowballsstemmer.stem('gose')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "R7iOb5eNgVZG",
        "outputId": "8c7b4ba4-d203-4ca8-c558-4240396811a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'go'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "stemming.stem('going')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Limitation              | Description                                              |\n",
        "| ----------------------- | -------------------------------------------------------- |\n",
        "| Not language-aware      | Doesn’t handle irregular words (e.g., \"went\" → not \"go\") |\n",
        "| Not a lemmatizer        | Doesn’t return dictionary forms                          |\n",
        "| Can under- or over-stem | e.g., “universe” → “univers”                             |\n"
      ],
      "metadata": {
        "id": "H6ufhdfXjCh3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U38S-pJrgVZH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgDTqgZygVZH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naNloAmjgVZI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpGhN1n1gVZI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
